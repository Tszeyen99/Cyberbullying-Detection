{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree\n",
    "from xml.etree import ElementTree\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir, path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated CSV file has been saved to: /Users/tszeyenthen/Python Study/jupyter notebbok/Cyberbullying/fyp/amica-cyberbullying-distribute/askfm-cyberbullying-data/concatenated_results.csv\n"
     ]
    }
   ],
   "source": [
    "def parse_xml(file_path, file_name):\n",
    "    tree = ElementTree.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    sentences = {}\n",
    "    non_role_annotation_counts = {}\n",
    "    unique_repr_texts = {}\n",
    "\n",
    "    roles_scores = {\n",
    "        'one_Harasser': ('Harasser', '1'),\n",
    "        'two_Harasser': ('Harasser', '2'),\n",
    "        'one_Victim' : ('Victim', '1'),\n",
    "        'two_Victim' : ('Victim', '2'),\n",
    "        'one_Bystander_defender' : ('Bystander_defender', '1'),\n",
    "        'two_Bystander_defender' : ('Bystander_defender', '2'),\n",
    "        'one_Bystander_assistant' : ('Bystander_assistant', '1'),\n",
    "        'two_Bystander_assistant' : ('Bystander_assistant', '2')\n",
    "    }\n",
    "\n",
    "    for sentence in root.findall(\".//sentence\"):\n",
    "        sentence_id = sentence.get('id').split('.')[1]\n",
    "        sentences[sentence_id] = {\n",
    "            'sentence_id' : f\"s.{sentence_id}\",\n",
    "            'text': \" \".join(word.text for word in sentence.findall(\".//word\") if word.text),\n",
    "            'Cyberbullying': 0,\n",
    "        }\n",
    "        non_role_annotation_counts[sentence_id] = 0\n",
    "        unique_repr_texts[sentence_id] = set()\n",
    "\n",
    "    all_labels = [\n",
    "        'General_insult', 'Assertive_selfdef', 'Curse_Exclusion', 'Threat_Blackmail', \n",
    "        'General_defense', 'Other_language', 'Powerless_selfdef', 'Encouraging_harasser',\n",
    "        'Harmless_sexual_talk', 'Good_characteristics', 'Sarcasm', 'Other', 'Defamation',\n",
    "        'Attacking_relatives', 'Sexism', 'Racism', 'Sexual_harassment'\n",
    "    ]\n",
    "\n",
    "    for annotation in root.findall(\".//annotation\"):\n",
    "        sentence_id = annotation.get('words').split('.')[1]\n",
    "        repr_text = annotation.get('repr').replace(\"&#182;\", \"Â¶\")\n",
    "        if repr_text in unique_repr_texts[sentence_id]:\n",
    "            continue\n",
    "        unique_repr_texts[sentence_id].add(repr_text)\n",
    "        sentences[sentence_id]['Cyberbullying'] = 1\n",
    "\n",
    "        role_found = False\n",
    "        for role, (role_desc, score) in roles_scores.items():\n",
    "            if role in annotation.keys():\n",
    "                sentences[sentence_id]['role'] = role_desc\n",
    "                sentences[sentence_id]['harmful_score'] = score\n",
    "                sentences[sentence_id]['words0'] = repr_text\n",
    "                role_found = True\n",
    "                break\n",
    "        \n",
    "        if not role_found:\n",
    "            index = non_role_annotation_counts[sentence_id]\n",
    "            words_key = f'words{index + 1}'\n",
    "            label_key = f'label{index + 1}'\n",
    "            non_role_annotation_counts[sentence_id] += 1\n",
    "\n",
    "            sentences[sentence_id][words_key] = repr_text\n",
    "\n",
    "            for label in all_labels:\n",
    "                if label in annotation.keys():\n",
    "                    sentences[sentence_id][label_key] = label\n",
    "                    break\n",
    "    \n",
    "    corrected_df = pd.DataFrame.from_dict(sentences, orient='index')\n",
    "    corrected_df['file_name'] = file_name\n",
    "\n",
    "    # column in desired order\n",
    "    dynamic_columns = []\n",
    "    max_annotations = max(non_role_annotation_counts.values())\n",
    "    for i in range(1, max_annotations +1):\n",
    "        if any(f'words{i}' in col for col in corrected_df.columns):\n",
    "            dynamic_columns.extend([f'words{i}', f'label{i}'])\n",
    "\n",
    "    base_columns = ['file_name', 'sentence_id', 'text', 'Cyberbullying', 'role', 'harmful_score', 'words0']\n",
    "    all_columns = base_columns + dynamic_columns\n",
    "    corrected_df = corrected_df.reindex(columns = all_columns)\n",
    "\n",
    "    return corrected_df\n",
    "\n",
    "def process_all_xml_files(directory_path):\n",
    "    all_dfs = [] #List to store df from each files\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith('.xml'):\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            df = parse_xml(file_path, file_name)\n",
    "            all_dfs.append(df)\n",
    "\n",
    "    concatenated_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    concatenated_df = concatenated_df[concatenated_df['text'].astype(str).str.strip() != '']\n",
    "    return concatenated_df\n",
    "\n",
    "xml_directory_path = '/Users/tszeyenthen/Python Study/jupyter notebbok/Cyberbullying/fyp/amica-cyberbullying-distribute/askfm-cyberbullying-data/xml_folder'\n",
    "\n",
    "final_df = process_all_xml_files(xml_directory_path)\n",
    "\n",
    "csv_file_path = '/Users/tszeyenthen/Python Study/jupyter notebbok/Cyberbullying/fyp/amica-cyberbullying-distribute/askfm-cyberbullying-data/concatenated_results.csv'\n",
    "\n",
    "final_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f'Concatenated CSV file has been saved to: {csv_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h2/q_r6y6bd5f5c9hvfsfnt31xr0000gn/T/ipykernel_4914/2251525095.py:6: DtypeWarning: Columns (21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(csv_file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Update 'Cyberbullying' to 0 where 'label1' is 'Other_language'\n",
    "final_df.loc[final_df['label1'] == 'Other_language', 'Cyberbullying'] = 0\n",
    "\n",
    "# Save the updated DataFrame back to CSV if needed\n",
    "final_df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Since the label columns are iterated (label1, label2, ...), \n",
    "# let's prepare to iterate through them\n",
    "max_label_number = 20  # Update this with the maximum number of label columns you have\n",
    "label_columns = [f'label{i}' for i in range(1, max_label_number + 1)]\n",
    "\n",
    "# Create a dictionary to store the counts for each unique label\n",
    "label_counts = {}\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for _, row in final_df.iterrows():\n",
    "    # Iterate through each label column in the row\n",
    "    for label_col in label_columns:\n",
    "        # Check if the label column exists in the DataFrame\n",
    "        if label_col in final_df.columns:\n",
    "            # If the label is not NaN (i.e., if it exists in the row)\n",
    "            if not pd.isna(row[label_col]):\n",
    "                # Get the label from the row\n",
    "                label = row[label_col]\n",
    "                # If the label is already in the dictionary, increment its count\n",
    "                if label in label_counts:\n",
    "                    label_counts[label] += 1\n",
    "                # Otherwise, add the label to the dictionary with a count of 1\n",
    "                else:\n",
    "                    label_counts[label] = 1\n",
    "\n",
    "# Now, let's create new columns for each label with binary values (1 or 0)\n",
    "for label in label_counts.keys():\n",
    "    # Initialize the column with zeros\n",
    "    final_df[label] = 0\n",
    "    # Iterate again over each row to set the value to 1 where the label is present\n",
    "    for idx, row in final_df.iterrows():\n",
    "        for label_col in label_columns:\n",
    "            if label_col in final_df.columns and label == row[label_col]:\n",
    "                final_df.at[idx, label] = 1\n",
    "                break  # Stop checking other label columns for this row if we've found a match\n",
    "\n",
    "# Show a summary of the updated DataFrame\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h2/q_r6y6bd5f5c9hvfsfnt31xr0000gn/T/ipykernel_4914/588774873.py:1: DtypeWarning: Columns (12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_df = pd.read_csv('/Users/tszeyenthen/Python Study/jupyter notebbok/Cyberbullying/fyp/amica-cyberbullying-distribute/askfm-cyberbullying-data/concatenated_results1.csv')\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.read_csv('/Users/tszeyenthen/Python Study/jupyter notebbok/Cyberbullying/fyp/amica-cyberbullying-distribute/askfm-cyberbullying-data/concatenated_results1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correctly identify NaN values in 'role' column and update 'Cyberbullying' accordingly\n",
    "final_df.loc[final_df['role'].isna(), 'Cyberbullying'] = 0\n",
    "\n",
    "# Save the updated DataFrame back to CSV\n",
    "final_df.to_csv('concatenated_results1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
